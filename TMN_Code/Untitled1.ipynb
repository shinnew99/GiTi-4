{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbdf00f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from nbformat.v4 import new_code_cell, new_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8293e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\" import torch\n",
    "from transformers import (\n",
    "    Wav2Vec2ForSequenceClassification,\n",
    "    BertForSequenceClassification,\n",
    "    RobertaForSequenceClassification\n",
    ")\n",
    "from torch import nn\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "from erc.constants import Task\n",
    "import erc\n",
    "from .cross_attention_utils import TransformerEncoder\n",
    "\n",
    "\n",
    "logger = erc.utils.get_logger(__name__)\n",
    "\n",
    "class CrossAttentionRoberta(nn.Module):\n",
    "    TASK = Task.ALL\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: str,\n",
    "        criterions: torch.nn.Module,\n",
    "        cls_coef: float = 0.7,\n",
    "        **config_kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.wav_model = Wav2Vec2ForSequenceClassification.from_pretrained(config['wav'])\n",
    "        self.txt_model = RobertaForSequenceClassification.from_pretrained(config['txt'])\n",
    "\n",
    "        last_hdn_size = {\n",
    "            \"klue/roberta-base\": 768, \"klue/roberta-large\": 1024\n",
    "        }[config[\"txt\"]]\n",
    "        \n",
    "        # Cross Attention\n",
    "        cross_attn_config = dict(embed_dim=last_hdn_size,\n",
    "                                 num_heads=8,\n",
    "                                 layers=1,\n",
    "                                 attn_dropout=0,\n",
    "                                 relu_dropout=0,\n",
    "                                 res_dropout=0,\n",
    "                                 embed_dropout=0,\n",
    "                                 attn_mask=None)\n",
    "        self.wav2txt = TransformerEncoder(**cross_attn_config)\n",
    "        self.txt2wav = TransformerEncoder(**cross_attn_config)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # Last mixer\n",
    "        dropout_p = 0.1\n",
    "        output_dim = 512\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(2 * last_hdn_size, output_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(output_dim, 9)\n",
    "        )\n",
    "        \n",
    "        self.use_peakl = config_kwargs.get(\"use_peakl\", False)\n",
    "        \n",
    "        # Loading Checkpoints\n",
    "        if config_kwargs.get(\"checkpoint\"):\n",
    "            for name, param in self.state_dict().items():\n",
    "                if param.requires_grad:\n",
    "                    print(name)\n",
    "            logger.info(\"Load from checkpoint\")\n",
    "            def parser(k):\n",
    "                _k = k.split(\".\")[1:]\n",
    "                if _k[0] == \"wav_model\" and _k[1] != \"classifier\":\n",
    "                    _k.insert(1, \"wav2vec2\")\n",
    "                elif _k[0] == \"txt_model\" and _k[1] != \"classifier\":\n",
    "                    _k.insert(1, \"roberta\")\n",
    "                return \".\".join(_k)\n",
    "            ckpt = {parser(k): v for k, v in config_kwargs[\"checkpoint\"].items()}\n",
    "            self.load_state_dict(ckpt, strict=False)\n",
    "            \n",
    "        # Setting up LORA\n",
    "        if \"lora\" in config:\n",
    "            logger.info(\"Train with Lora\")\n",
    "            pcfg_wav = LoraConfig(task_type=TaskType.SEQ_CLS, **config[\"lora\"][\"wav\"])\n",
    "            self.wav_model = get_peft_model(self.wav_model, pcfg_wav)\n",
    "            pcfg_txt = LoraConfig(task_type=TaskType.SEQ_CLS, **config[\"lora\"][\"txt\"])\n",
    "            self.txt_model = get_peft_model(self.txt_model, pcfg_txt)\n",
    "        \n",
    "        # Retrieving Encoders\n",
    "        self.wav_model = self.wav_model.wav2vec2\n",
    "        self.txt_model = self.txt_model.roberta\n",
    "\n",
    "        self.criterions = criterions\n",
    "        if not (0 < cls_coef < 1):\n",
    "            cls_coef = 0.7\n",
    "        self.cls_coef = cls_coef\n",
    "        self.reg_coef = 1 - cls_coef\n",
    "\n",
    "    def forward(self,\n",
    "                wav: torch.Tensor,\n",
    "                wav_mask: torch.Tensor,\n",
    "                txt: torch.Tensor,\n",
    "                txt_mask: torch.Tensor,\n",
    "                labels: torch.Tensor = None,\n",
    "                **kwargs) -> dict:\n",
    "        # Size\n",
    "         # WAV_hidden_dim: 1024\n",
    "         # WAV_proj_size: 256\n",
    "         # RoBERTa_hidden_dim: 1024 (large)\n",
    "         # RoBERTa_proj_size: 256\n",
    "        \n",
    "        # Get Wave Hidden States\n",
    "        wav = self.wav_model(input_values=wav, attention_mask=wav_mask).last_hidden_state # (B, S, WAV_hidden_dim)\n",
    "        wav = wav.permute(1, 0, 2) # (S, B, WAV_hidden_dim)\n",
    "\n",
    "        # Get Text Hidden States \n",
    "        txt = self.txt_model(input_ids=txt, attention_mask=txt_mask).last_hidden_state # (B, seq_len RoBERTa_hidden_dim)\n",
    "        txt = txt.permute(1, 0, 2) # (S, B, RoBERTa_hidden_dim)\n",
    "\n",
    "        # Cross Attention\n",
    "        cross_w2t = self.wav2txt(wav, txt, txt).permute(1, 2, 0) # (B, proj_size, seq_len)\n",
    "        cross_w2t = self.avgpool(cross_w2t) # (B, proj_size)\n",
    "        cross_w2t = cross_w2t.squeeze(dim=-1)\n",
    "        cross_t2w = self.txt2wav(txt, wav, wav).permute(1, 0, 2) # (B, seq_len, proj_size)\n",
    "        cross_t2w = cross_t2w[:, 0, :] # (B, proj_size), cls_token only\n",
    "        \n",
    "        output = torch.cat([cross_w2t, cross_t2w], dim=1)\n",
    "        logits = self.classifier(output)\n",
    "        \n",
    "        # Calculate Loss\n",
    "        cls_logits = logits[:, :-2]\n",
    "        cls_labels = labels[\"emotion\"]\n",
    "        if cls_labels.ndim == 1: # Single label case\n",
    "            cls_loss = self.criterions[\"cls\"](cls_logits, cls_labels.long())\n",
    "        elif cls_labels.ndim == 2: # Multi label case\n",
    "            if self.use_peakl:\n",
    "                cls_labels = erc.utils.apply_peakl(logits=cls_labels)\n",
    "            cls_loss = self.criterions[\"cls\"](cls_logits, cls_labels.float())\n",
    "        \n",
    "        reg_logits = logits[:, -2:]\n",
    "        reg_loss = self.criterions[\"reg\"](reg_logits, labels[\"regress\"].float())\n",
    "\n",
    "        total_loss = cls_loss * self.cls_coef + reg_loss * self.reg_coef\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"cls_loss\": cls_loss.detach().cpu(),\n",
    "            \"reg_loss\": reg_loss.detach().cpu(),\n",
    "            \"emotion\": cls_labels.detach(),\n",
    "            \"regress\": labels[\"regress\"].detach().float(),\n",
    "            \"cls_pred\": cls_logits.detach(),\n",
    "            \"reg_pred\": reg_logits.detach().float(),\n",
    "        } \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
